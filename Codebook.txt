Codebook - Coursera project - Jeff Hedberg
=============
	This dataset is an aggregated version of the "Human Activity Recognition Using Smartphones Dataset Version 1.0" 
	created by Jorge L. Reyes-Ortiz, Davide Anguita, Alessandro Ghio, Luca Oneto.
	Smartlab - Non Linear Complex Systems Laboratory
	DITEN - Università degli Studi di Genova.
	Via Opera Pia 11A, I-16145, Genoa, Italy.
	activityrecognition@smartlab.ws
	www.smartlab.ws
	
	License:
	========
	Use of this dataset in publications must be acknowledged by referencing the following publication [1] 

	[1] Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition
	on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. 
	International Workshop of Ambient Assisted Living (IWAAL 2012). Vitoria-Gasteiz, Spain. Dec 2012

	This dataset is distributed AS-IS and no responsibility implied or explicit can be addressed to the authors or their institutions for its use or misuse. Any commercial use is prohibited.

	Jorge L. Reyes-Ortiz, Alessandro Ghio, Luca Oneto, Davide Anguita. November 2012.
=============

List of the features, as well as the description of the base data that the aggregates were created from is displayed below. Columns 1-79 have the prefix of "avg_", since they are all averages of the measurement values for each grouping variable combination.  The grouping variables are in columns 80-81, and are "subject_id", and "activity_name" respectively.  Additional information on the base smartphone raw dataset can be found at the bottom of this document.  The dataset has a size of 81 x 180  (6 activities and 30 subjects for each of 79 measurements +2 grouping variables).

1	avg_tBodyAcc_mean_X
2	avg_tBodyAcc_mean_Y
3	avg_tBodyAcc_mean_Z
4	avg_tBodyAcc_std_X
5	avg_tBodyAcc_std_Y
6	avg_tBodyAcc_std_Z
7	avg_tGravityAcc_mean_X
8	avg_tGravityAcc_mean_Y
9	avg_tGravityAcc_mean_Z
10	avg_tGravityAcc_std_X
11	avg_tGravityAcc_std_Y
12	avg_tGravityAcc_std_Z
13	avg_tBodyAccJerk_mean_X
14	avg_tBodyAccJerk_mean_Y
15	avg_tBodyAccJerk_mean_Z
16	avg_tBodyAccJerk_std_X
17	avg_tBodyAccJerk_std_Y
18	avg_tBodyAccJerk_std_Z
19	avg_tBodyGyro_mean_X
20	avg_tBodyGyro_mean_Y
21	avg_tBodyGyro_mean_Z
22	avg_tBodyGyro_std_X
23	avg_tBodyGyro_std_Y
24	avg_tBodyGyro_std_Z
25	avg_tBodyGyroJerk_mean_X
26	avg_tBodyGyroJerk_mean_Y
27	avg_tBodyGyroJerk_mean_Z
28	avg_tBodyGyroJerk_std_X
29	avg_tBodyGyroJerk_std_Y
30	avg_tBodyGyroJerk_std_Z
31	avg_tBodyAccMag_mean
32	avg_tBodyAccMag_std
33	avg_tGravityAccMag_mean
34	avg_tGravityAccMag_std
35	avg_tBodyAccJerkMag_mean
36	avg_tBodyAccJerkMag_std
37	avg_tBodyGyroMag_mean
38	avg_tBodyGyroMag_std
39	avg_tBodyGyroJerkMag_mean
40	avg_tBodyGyroJerkMag_std
41	avg_fBodyAcc_mean_X
42	avg_fBodyAcc_mean_Y
43	avg_fBodyAcc_mean_Z
44	avg_fBodyAcc_std_X
45	avg_fBodyAcc_std_Y
46	avg_fBodyAcc_std_Z
47	avg_fBodyAcc_meanFreq_X
48	avg_fBodyAcc_meanFreq_Y
49	avg_fBodyAcc_meanFreq_Z
50	avg_fBodyAccJerk_mean_X
51	avg_fBodyAccJerk_mean_Y
52	avg_fBodyAccJerk_mean_Z
53	avg_fBodyAccJerk_std_X
54	avg_fBodyAccJerk_std_Y
55	avg_fBodyAccJerk_std_Z
56	avg_fBodyAccJerk_meanFreq_X
57	avg_fBodyAccJerk_meanFreq_Y
58	avg_fBodyAccJerk_meanFreq_Z
59	avg_fBodyGyro_mean_X
60	avg_fBodyGyro_mean_Y
61	avg_fBodyGyro_mean_Z
62	avg_fBodyGyro_std_X
63	avg_fBodyGyro_std_Y
64	avg_fBodyGyro_std_Z
65	avg_fBodyGyro_meanFreq_X
66	avg_fBodyGyro_meanFreq_Y
67	avg_fBodyGyro_meanFreq_Z
68	avg_fBodyAccMag_mean
69	avg_fBodyAccMag_std
70	avg_fBodyAccMag_meanFreq
71	avg_fBodyBodyAccJerkMag_mean
72	avg_fBodyBodyAccJerkMag_std
73	avg_fBodyBodyAccJerkMag_meanFreq
74	avg_fBodyBodyGyroMag_mean
75	avg_fBodyBodyGyroMag_std
76	avg_fBodyBodyGyroMag_meanFreq
77	avg_fBodyBodyGyroJerkMag_mean
78	avg_fBodyBodyGyroJerkMag_std
79	avg_fBodyBodyGyroJerkMag_meanFreq
80	subject_id
81	activity_name

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
This is sourced from 	http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones
			http://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Description of Base data that was used to create the aggregated dataset described above:
=================

The features selected for this database come from the accelerometer and gyroscope 3-axial raw signals tAcc-XYZ and tGyro-XYZ. These time domain signals (prefix 't' to denote time) were captured at a constant rate of 50 Hz. Then they were filtered using a median filter and a 3rd order low pass Butterworth filter with a corner frequency of 20 Hz to remove noise. Similarly, the acceleration signal was then separated into body and gravity acceleration signals (tBodyAcc-XYZ and tGravityAcc-XYZ) using another low pass Butterworth filter with a corner frequency of 0.3 Hz. 

Subsequently, the body linear acceleration and angular velocity were derived in time to obtain Jerk signals (tBodyAccJerk-XYZ and tBodyGyroJerk-XYZ). Also the magnitude of these three-dimensional signals were calculated using the Euclidean norm (tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag, tBodyGyroJerkMag). 

Finally a Fast Fourier Transform (FFT) was applied to some of these signals producing fBodyAcc-XYZ, fBodyAccJerk-XYZ, fBodyGyro-XYZ, fBodyAccJerkMag, fBodyGyroMag, fBodyGyroJerkMag. (Note the 'f' to indicate frequency domain signals). 

These signals were used to estimate variables of the feature vector for each pattern:  
'-XYZ' is used to denote 3-axial signals in the X, Y and Z directions.

tBodyAcc-XYZ
tGravityAcc-XYZ
tBodyAccJerk-XYZ
tBodyGyro-XYZ
tBodyGyroJerk-XYZ
tBodyAccMag
tGravityAccMag
tBodyAccJerkMag
tBodyGyroMag
tBodyGyroJerkMag
fBodyAcc-XYZ
fBodyAccJerk-XYZ
fBodyGyro-XYZ
fBodyAccMag
fBodyAccJerkMag
fBodyGyroMag
fBodyGyroJerkMag

The set of variables that were estimated from these signals are: 

mean(): Mean value
std(): Standard deviation
mad(): Median absolute deviation 
max(): Largest value in array
min(): Smallest value in array
sma(): Signal magnitude area
energy(): Energy measure. Sum of the squares divided by the number of values. 
iqr(): Interquartile range 
entropy(): Signal entropy
arCoeff(): Autorregresion coefficients with Burg order equal to 4
correlation(): correlation coefficient between two signals
maxInds(): index of the frequency component with largest magnitude
meanFreq(): Weighted average of the frequency components to obtain a mean frequency
skewness(): skewness of the frequency domain signal 
kurtosis(): kurtosis of the frequency domain signal 
bandsEnergy(): Energy of a frequency interval within the 64 bins of the FFT of each window.
angle(): Angle between to vectors.

Additional vectors obtained by averaging the signals in a signal window sample. These are used on the angle() variable:

gravityMean
tBodyAccMean
tBodyAccJerkMean
tBodyGyroMean
tBodyGyroJerkMean

The complete list of variables of each feature vector is available in 'features.txt'
